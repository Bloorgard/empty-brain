LM Studio — это супер простая штука: установил, скачал модель и запустил. В интернете куча туториалов. К тому же, она использует llama.cpp, а это значит, что тебе нужны модели с расширением .gguf. Сейчас это самый распространённый формат, и его отлично поддерживают. Какую модель запускать — зависит от памяти твоей видеокарты. В общем:

4GB VRAM -> Запускай Gemma 2B, Phi 3 Mini на Q8 или Llama 3 8B/ Gemma 9B на Q4  
8GB VRAM -> Запускай Llama 3 8B/ Gemma 9B на Q8  
16GB VRAM -> Запускай Gemma 27B/ Command R 35B на Q4  
24GB VRAM -> Запускай Gemma 27B на Q6 или Llama 3 70B на Q2 (Низкое квантование, не рекомендуется для кодинга)

Квантование (Q2, Q4 и т.д.) — это как сжатые версии модели. Q8 — очень высокое качество (разницы почти не заметишь). Q6 тоже довольно высокое, близко к Q8. Q4 — среднее, но всё ещё неплохое. Q2 сойдёт для больших моделей для задач не связанных с кодингом, но оно жёстко режет их интеллект. (Для маленьких моделей — слишком сильное "сжатие", теряется много интеллекта)

Что касается векторизации, LM Studio немного поддерживает модели для эмбеддингов: они рекомендуют Nomic Embed v1.5, он лёгкий и довольно неплохой. Плюс его легко использовать, потому что есть локальный API типа OpenAI.